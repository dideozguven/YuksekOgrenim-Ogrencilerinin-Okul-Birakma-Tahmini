# ğŸ“ Ã–ÄŸrenci BaÅŸarÄ± Tahmini: Veri MadenciliÄŸi ile Modelleme
Bu proje, yÃ¼ksekÃ¶ÄŸrenim dÃ¼zeyindeki Ã¶ÄŸrencilerin akademik baÅŸarÄ±larÄ±nÄ± tahmin etmek amacÄ±yla makine Ã¶ÄŸrenmesi algoritmalarÄ± kullanÄ±larak gerÃ§ekleÅŸtirilmiÅŸtir. Veri madenciliÄŸi sÃ¼reÃ§leri ve farklÄ± sÄ±nÄ±flandÄ±rma teknikleri ile â€œDropoutâ€, â€œEnrolledâ€ ve â€œGraduateâ€ olmak Ã¼zere Ã¼Ã§ sÄ±nÄ±fta sÄ±nÄ±flandÄ±rma yapÄ±lmÄ±ÅŸtÄ±r.

## ğŸ“Œ **Proje AmacÄ±**

EÄŸitim hayatÄ±nda Ã¶ÄŸrencilerin baÅŸarÄ±sÄ±nÄ± erken safhada tahmin ederek:

- Riskli Ã¶ÄŸrencilerin tespit edilmesi,

- Rehberlik ve destek sÃ¼reÃ§lerinin iyileÅŸtirilmesi,

- EÄŸitim kurumlarÄ±nÄ±n karar destek sistemlerine katkÄ± saÄŸlanmasÄ± hedeflenmiÅŸtir.

## ğŸ§ KullanÄ±lan YÃ¶ntemler

Makine Ã–ÄŸrenmesi AlgoritmalarÄ±:

- Decision Tree

- Random Forest

- XGBoost

## Veri Ã–n Ä°ÅŸleme

- Eksik veri kontrolÃ¼

- Kategorik verilerin etiketlenmesi (Label Encoding)

- SMOTE ile veri dengeleme

## Performans DeÄŸerlendirme

- DoÄŸruluk (Accuracy)

- F1-Score (sÄ±nÄ±f bazlÄ± ve ortalama)

- Confusion Matrix

- GÃ¼ven AralÄ±ÄŸÄ± HesaplamalarÄ± (Bootstrap yÃ¶ntemi)

## ğŸ“ Veri Seti Bilgisi

Bu projede kullanÄ±lan veri seti, UCI Machine Learning Repository (https://archive.ics.uci.edu/) Ã¼zerinden temin edilmiÅŸtir. Toplamda 4424 gÃ¶zlem ve 37 Ã¶zellik iÃ§eren bu veri seti, Ã¶ÄŸrencilerin demografik yapÄ±larÄ±, akademik geÃ§miÅŸleri ve sosyoekonomik durumlarÄ±na iliÅŸkin geniÅŸ bir yelpazede bilgi sunmaktadÄ±r. Ã–znitelikler Ã¼Ã§ ana grupta toplanabilir: Demografik bilgiler (cinsiyet, yaÅŸ, uyruk, medeni durum, ebeveyn meslek ve eÄŸitim durumu), akademik bilgiler (Ã¼niversiteye giriÅŸ notu, Ã¶nceki eÄŸitim notu, dÃ¶nemlik ders ve sÄ±nav sayÄ±larÄ±, ders geÃ§me durumu) ve sosyoekonomik bilgiler (harÃ§ Ã¶deme dÃ¼zeni, burs durumu, borÃ§luluk, iÅŸsizlik ve enflasyon oranÄ±). Modelleme sÃ¼recinde hedef deÄŸiÅŸken olarak Target sÃ¼tunu kullanÄ±lmÄ±ÅŸtÄ±r ve bu sÃ¼tun, Ã¶ÄŸrencinin akademik durumunu Ã¼Ã§ farklÄ± sÄ±nÄ±fta belirtmektedir: Dropout (okulu bÄ±rakmÄ±ÅŸ), Enrolled (kayÄ±tlÄ±) ve Graduate (mezun).


Hedef deÄŸiÅŸkenin sÄ±nÄ±f daÄŸÄ±lÄ±mÄ±na bakÄ±ldÄ±ÄŸÄ±nda, 2209 Ã¶ÄŸrenci mezun, 1421 Ã¶ÄŸrenci okulu bÄ±rakmÄ±ÅŸ ve yalnÄ±zca 794 Ã¶ÄŸrenci hÃ¢lÃ¢ kayÄ±tlÄ± durumdadÄ±r. Bu daÄŸÄ±lÄ±m, sÄ±nÄ±flar arasÄ±nda belirgin bir dengesizlik olduÄŸunu gÃ¶stermektedir. Ã–zellikle â€œEnrolledâ€ sÄ±nÄ±fÄ± sayÄ±ca azÄ±nlÄ±kta olduÄŸu iÃ§in bu sÄ±nÄ±fÄ±n Ã¶ÄŸrenilmesi makine Ã¶ÄŸrenmesi algoritmalarÄ± aÃ§Ä±sÄ±ndan daha zorlayÄ±cÄ± hale gelmektedir. Bu nedenle modelleme sÃ¼recinde, sÄ±nÄ±f dengesizliÄŸini gidermek amacÄ±yla SMOTE (Synthetic Minority Over-sampling Technique) gibi veri dengeleme teknikleri kullanÄ±lmÄ±ÅŸtÄ±r.

## ğŸ“Š Veri KeÅŸfi ve GÃ¶rselleÅŸtirme

- Histogramlar ile daÄŸÄ±lÄ±m analizi

- Boxplot ile sayÄ±sal deÄŸiÅŸkenlerin Target'a gÃ¶re karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±

- Countplot ile kategorik deÄŸiÅŸkenlerin sÄ±nÄ±flara gÃ¶re daÄŸÄ±lÄ±mÄ±

- **Ã–ne Ã§Ä±kan bulgular:**

- GÃ¼ndÃ¼z Ã¶ÄŸretiminde mezuniyet oranÄ± daha yÃ¼ksek.

- KadÄ±n Ã¶ÄŸrencilerin baÅŸarÄ± oranÄ± erkeklere gÃ¶re daha fazla.

- HarÃ§ Ã¶demelerini dÃ¼zenli yapanlar mezun olma eÄŸiliminde.

## ğŸ”§ Veri Ã–n Ä°ÅŸleme

- Eksik Veri: HiÃ§bir deÄŸiÅŸkende eksik veri bulunmamaktadÄ±r.

- Encoding: Hedef deÄŸiÅŸken sayÄ±sallaÅŸtÄ±rÄ±ldÄ± (Graduate=2, Enrolled=1, Dropout=0).

- Dengeleme: SMOTE kullanÄ±larak sÄ±nÄ±f dengesizliÄŸi giderildi.

## ğŸ¤– Modelleme ve SonuÃ§lar
### 1. Decision Tree

- DoÄŸruluk (SMOTE ile): %65.5

- Enrolled sÄ±nÄ±fÄ± F1-score: %43

- Ã–zellik Ã¶nemi: En etkili deÄŸiÅŸken Curricular units 2nd sem (approved)

- Parametre denemeleri: max_depth, criterion varyasyonlarÄ± ile optimize edildi

### 2. Random Forest

- DoÄŸruluk (SMOTE ile): %73.3

- Enrolled sÄ±nÄ±fÄ± F1-score: %50

- AvantajÄ±: DÃ¼ÅŸÃ¼k varyans, yÃ¼ksek genelleme

- Overfitting Testi: EÄŸitim ve test doÄŸruluklarÄ± Ã§ok yakÄ±ndÄ± â†’ overfitting yok

### 3. XGBoost

- DoÄŸruluk (SMOTE ile): %76.5

- Enrolled sÄ±nÄ±fÄ± F1-score: %54

- AvantajÄ±: Hem genel doÄŸruluk hem de sÄ±nÄ±f bazlÄ± baÅŸarÄ±da en yÃ¼ksek performans

- GÃ¼ven AralÄ±ÄŸÄ±: Bootstrap ile doÄŸruluk oranÄ± [0.7440, 0.7877]

## ğŸ“ˆ Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

Model	Accuracy	F1-Score (0)	F1-Score (1)	F1-Score (2)	Macro Avg	Weighted Avg
Decision Tree + SMOTE	0.6551	0.71	0.43	0.75	0.63	0.68
Random Forest + SMOTE	0.7334	0.72	0.50	0.84	0.69	0.74
XGBoost + SMOTE	0.7651	0.77	0.54	0.85	0.72	0.77

ğŸ“Œ SonuÃ§: XGBoost modeli, sÄ±nÄ±f dengesini koruyarak en yÃ¼ksek baÅŸarÄ±yÄ± gÃ¶stermiÅŸtir.


## ğŸ”¬ Teknik Detaylar

- Programlama Dili: Python 3.11

- KullanÄ±lan KÃ¼tÃ¼phaneler: pandas, numpy, matplotlib, seaborn, sklearn: preprocessing, model_selection, metrics, DecisionTreeClassifier, RandomForestClassifier, xgboost, imblearn: SMOTE

## âœ… SonuÃ§ ve KatkÄ±lar

- SMOTE sayesinde sÄ±nÄ±f dengesizliÄŸi Ã¶nemli Ã¶lÃ§Ã¼de giderildi.

- XGBoost modeli hem genel baÅŸarÄ±da hem de azÄ±nlÄ±k sÄ±nÄ±flarda gÃ¼Ã§lÃ¼ sonuÃ§lar verdi.

- Bootstrap yÃ¶ntemi ile model gÃ¼venilirliÄŸi istatistiksel olarak ispatlandÄ±.
## Youtube Video Linki

Projenin detaylÄ± anlatÄ±ldÄ±ÄŸÄ± video iÃ§in: https://youtu.be/gFA8yxTr-dc

## ğŸ“Œ Gelecek Ã‡alÄ±ÅŸmalar

- CatBoost, LightGBM gibi alternatif modeller ile karÅŸÄ±laÅŸtÄ±rmalar yapÄ±labilir.

- Ã–zellik seÃ§imi (feature selection) algoritmalarÄ± ile model sadeleÅŸtirilebilir.

- Weka veya AutoML platformlarÄ±yla modelleme tekrarlanabilir.

Proje Sahibi:

Fatma Didenur Ã–zgÃ¼ven

Veri MadenciliÄŸine GiriÅŸ â€“ 2024-2025 Bahar DÃ¶nemi

Bursa Teknik Ãœniversitesi
