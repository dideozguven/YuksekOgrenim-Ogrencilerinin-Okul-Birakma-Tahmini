# -*- coding: utf-8 -*-
"""VeriMadenciligi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bV5qktGyP1u-72le0FlE-AgDIVdnTXbv

**Veri Keşfi ve Veri Önişleme**
"""

# Gerekli kütüphanelerin tanımlanması
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style="whitegrid")

df = pd.read_csv("data.csv", sep=';') # Veri setinin yüklenmesi

# İlk 5 satırı inceliyoruz
print(df.head())

# Veri yapısını inceleme
print(df.info())

# Veri setinde eksik veri olup olmadığına bakıyoruz. Sonuca göre, eğer eksik veri varsa medyan, ortalama vs. ile dolduracağız.
print(df.isnull().sum())

# İstatistiksel özet
df.describe(include='all')

# Hedef değişkenin dağılımı
print(df['Target'].value_counts())

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(6, 4))
ax = sns.countplot(data=df, x='Target', palette='pastel')
plt.title("Hedef Değişken Dağılımı")
plt.xlabel("Sınıf")
plt.ylabel("Öğrenci Sayısı")

for p in ax.patches:
    height = p.get_height()
    ax.annotate(f'{height}', (p.get_x() + p.get_width() / 2., height),
                ha='center', va='bottom', fontsize=10)

plt.show()

# Değişkenlerin histogram grafiği
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns

df[numeric_cols].hist(bins=20, figsize=(20, 15), color='skyblue', edgecolor='black')
plt.tight_layout()
plt.show()

# Kategorik verilerin Target özelliğine göre countplot ile görselleştirilmesi
# Dikkat! Bu veriler daha öncesinde encoding uygulandığı için int veya float formatında gözüküyor olabilir. Ancak bu veriler kategorik oldğu için boxplot ile gösterim
# yapılmak yerine barplot/countplot ile görselleştirme yapılmalıdır.
import matplotlib.pyplot as plt
import seaborn as sns

categorical_features = [
    'Gender',
    'Marital status',
    'Application mode',
    'Application order',
    'Course',
    'Daytime/evening attendance\t',
    'Previous qualification',
    'Nacionality',
    "Mother's qualification",
    "Father's qualification",
    "Mother's occupation",
    "Father's occupation",
    'Displaced',
    'Educational special needs',
    'Debtor',
    'Tuition fees up to date',
    'Scholarship holder',
    'International'
]

for feature in categorical_features:
    plt.figure(figsize=(10,5))
    sns.countplot(data=df, x=feature, hue='Target')
    plt.title(f'Countplot of {feature} by Target')
    plt.xticks(rotation=45, ha='right')
    plt.legend(title='Target')
    plt.tight_layout()
    plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Sayısal özelliklerin boxplot ile görselleştirilmesi
numeric_features = [
    'Previous qualification (grade)',
    'Admission grade',
    'Age at enrollment',
    'Curricular units 1st sem (credited)',
    'Curricular units 1st sem (enrolled)',
    'Curricular units 1st sem (evaluations)',
    'Curricular units 1st sem (approved)',
    'Curricular units 1st sem (grade)',
    'Curricular units 1st sem (without evaluations)',
    'Curricular units 2nd sem (credited)',
    'Curricular units 2nd sem (enrolled)',
    'Curricular units 2nd sem (evaluations)',
    'Curricular units 2nd sem (approved)',
    'Curricular units 2nd sem (grade)',
    'Curricular units 2nd sem (without evaluations)',
    'Unemployment rate',
    'Inflation rate',
    'GDP'
]

for feature in numeric_features:
    plt.figure(figsize=(8,5))
    sns.boxplot(data=df, x='Target', y=feature)
    plt.title(f'Boxplot of {feature} by Target')
    plt.xlabel('Target')
    plt.ylabel(feature)
    plt.tight_layout()
    plt.show()

# Bu aşamada 'Target' değişkeni için encoding işlemi uyguluyoruz.Veri setinin içinde başka kategorik veriler de bulunuyor ancak bunlar daha öncesinde sayısallaştırıldığı için
# bu özelliklere encoding işlemi uygulamıyoruz.
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['Target_encoded'] = le.fit_transform(df['Target'])

# Kodlama sonucu
# Graduate → 2
# Enrolled  → 1
# Dropout → 0

print(dict(zip(le.classes_, le.transform(le.classes_))))

"""**Veri Bölme ve Model Kurulumu**

**DECISION TREE MODELİ**
"""

from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split

X = df.drop(['Target_encoded','Target'], axis=1, errors='ignore')
y = df['Target_encoded']

# Eğitim ve test verisi olarak ayırma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# DecisionTreeClassifier modelini oluşturma ve eğitme
clf = DecisionTreeClassifier(random_state=42)
clf.fit(X_train, y_train)

# Test verisi ile tahmin yapma
y_pred = clf.predict(X_test)
# Sonuçları yazdırıyoruz
print("Accuracy:", accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

import pandas as pd
import matplotlib.pyplot as plt

# Özellik isimleriyle birlikte önemleri dataframe olarak gösteriyoruz
feature_importances = pd.DataFrame({
    'Feature': X.columns,
    'Importance': clf.feature_importances_
})

# Önem sırasına göre sırala
feature_importances = feature_importances.sort_values(by='Importance', ascending=False)

# En önemli 10 özelliği görselleştir
plt.figure(figsize=(10,6))
plt.barh(feature_importances['Feature'][:10][::-1], feature_importances['Importance'][:10][::-1])
plt.xlabel('Importance')
plt.title('Top 10 Most Important Features')
plt.tight_layout()
plt.show()

# İlk birkaç önemli özelliği yazdır
print(feature_importances.head(10))

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split

# Hedef değişkeni ve bağımsız değişkenleri ayırırken Target_encoded ve hedef değişkenleri çıkarıyoruz
X = df.drop(['Target_encoded','Target'], axis=1, errors='ignore')
y = df['Target_encoded']

# Veriyi eğitim ve test olarak %70 - %30 olacak şekilde bölüyoruz, sınıfların oranı korunuyor (stratify)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# Decision Tree sınıflandırıcı oluşturuyoruz
clf = DecisionTreeClassifier(
    criterion='gini',     # impurity ölçütü: 'gini'
    max_depth=5,          # ağacın maksimum derinliği
    random_state=42
)

# Modeli eğitim verisi ile eğitiyoruz
clf.fit(X_train, y_train)

# Test verisi ile tahmin yapıyoruz
y_pred = clf.predict(X_test)

# Sonuçları yazdırıyoruz
print("Accuracy:", accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split

# Hedef değişkeni ve bağımsız değişkenleri ayırırken Target_encoded ve hedef değişkenleri çıkarıyoruz
X = df.drop(['Target_encoded','Target'], axis=1, errors='ignore')
y = df['Target_encoded']

# Veriyi eğitim ve test olarak %70 - %30 olacak şekilde bölüyoruz, sınıfların oranı korunuyor (stratify)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# Decision Tree sınıflandırıcı oluşturuyoruz
clf = DecisionTreeClassifier(
    criterion='entropy',     # impurity ölçütü: 'entropi'
    max_depth=5,          # ağacın maksimum derinliği
    random_state=42
)

# Modeli eğitim verisi ile eğitiyoruz
clf.fit(X_train, y_train)

# Test verisi ile tahmin yapıyoruz
y_pred = clf.predict(X_test)

# Sonuçları yazdırıyoruz
print("Accuracy:", accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split

# Hedef değişkeni ve bağımsız değişkenleri ayırırken Target_encoded ve hedef değişkenleri çıkarıyoruz
X = df.drop(['Target_encoded','Target'], axis=1, errors='ignore')
y = df['Target_encoded']

# Veriyi eğitim ve test olarak %70 - %30 olacak şekilde bölüyoruz, sınıfların oranı korunuyor (stratify)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# Decision Tree sınıflandırıcı oluşturuyoruz
clf = DecisionTreeClassifier(
    criterion='gini',     # impurity ölçütü: 'gini'
    max_depth=4,          # ağacın maksimum derinliği
    random_state=42
)

# Modeli eğitim verisi ile eğitiyoruz
clf.fit(X_train, y_train)

# Test verisi ile tahmin yapıyoruz
y_pred = clf.predict(X_test)

# Sonuçları yazdırıyoruz
print("Accuracy:", accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

pip install imbalanced-learn

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE  # pip install imbalanced-learn

# Hedef ve bağımsız değişkenleri ayırıyoruz
X = df.drop(['Target_encoded','Target'], axis=1, errors='ignore')
y = df['Target_encoded']

# Veriyi eğitim-test olarak bölme
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# SMOTE ile azınlık sınıfını çoğaltma (sadece eğitim verisine)
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

# Model oluşturma ve eğitme (max_depth=4)
clf = DecisionTreeClassifier(
    criterion='gini',
    max_depth=4,
    random_state=42
)
clf.fit(X_train_res, y_train_res)

# Test setiyle tahmin yapma
y_pred = clf.predict(X_test)

# Sonuçları yazdırma
print("Accuracy:", accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

# Ağacı görselleştirme
plt.figure(figsize=(20,10))
plot_tree(
    clf,
    filled=True,
    feature_names=X.columns,
    class_names=[str(cls) for cls in clf.classes_],
    rounded=True,
    fontsize=10
)
plt.title("Decision Tree (max_depth=4)")
plt.show()

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
import numpy as np
import scipy.stats as st

# Özellikler ve hedef
X = df.drop(['Target_encoded','Target'], axis=1, errors='ignore')
y = df['Target_encoded']

# Eğitim-test bölme (Stratify ile)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# SMOTE ile eğitim verisini dengeleme
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

# Modeli oluşturma
clf = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=42)

# Cross-validation için stratified k-fold oluşturma
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)


# Modeli SMOTE ile dengelenmiş eğitim verisi ile eğit ve test seti üzerinde test etme
clf.fit(X_train_res, y_train_res)
y_pred = clf.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print("Accuracy:", acc)

# Güven aralığı için manuel bootstrap yöntemi

from sklearn.utils import resample

n_bootstraps = 1000
rng = np.random.RandomState(42)
bootstrapped_scores = []

for i in range(n_bootstraps):
    # Test setinden bootstrap örneklemi al
    indices = rng.randint(0, len(X_test), len(X_test))
    X_test_boot = X_test.iloc[indices]
    y_test_boot = y_test.iloc[indices]

    # Tahmin yap
    y_pred_boot = clf.predict(X_test_boot)

    # Doğruluk hesapla
    score = accuracy_score(y_test_boot, y_pred_boot)
    bootstrapped_scores.append(score)

bootstrapped_scores = np.array(bootstrapped_scores)
mean_acc = np.mean(bootstrapped_scores)
conf_int = st.t.interval(confidence=0.95, df=len(bootstrapped_scores)-1,
                        loc=mean_acc,
                        scale=st.sem(bootstrapped_scores))


print(f"Bootstrap Mean Accuracy: {mean_acc:.4f}")
print(f"95% Confidence Interval for Accuracy: ({conf_int[0]:.4f}, {conf_int[1]:.4f})")

"""**RANDOM FOREST MODELİ**"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Özellikler ve hedef değişken
X = df.drop(['Target_encoded', 'Target'], axis=1, errors='ignore')
y = df['Target_encoded']

# Veriyi %70 eğitim, %30 test olarak böl (sınıf oranını koru)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# Random Forest sınıflandırıcı oluştur
clf = RandomForestClassifier(
    n_estimators=100,    # ağaç sayısı
    max_depth=4,      # derinlik sınırı
    random_state=42
)

# Modeli eğit
clf.fit(X_train, y_train)

# Test üzerinde tahmin yap
y_pred = clf.predict(X_test)

# Sonuçları yazdır
print("Accuracy:", accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE

# Özellikler ve hedef değişken
X = df.drop(['Target_encoded', 'Target'], axis=1, errors='ignore')
y = df['Target_encoded']

# Veriyi %70 eğitim, %30 test olarak böl (sınıf oranını koru)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# SMOTE ile eğitim verisini dengele
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Random Forest sınıflandırıcı oluştur
clf = RandomForestClassifier(
    n_estimators=100,
    random_state=42,
    max_depth=4
)

# Modeli SMOTE ile dengelenmiş veride eğit
clf.fit(X_train_smote, y_train_smote)

# Test üzerinde tahmin yap
y_pred = clf.predict(X_test)

# Sonuçları yazdır
print("Accuracy:", accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.tree import plot_tree

# İlk ağacı çiz (clf.estimators_ listesinden)
plt.figure(figsize=(20, 10))
plot_tree(
    clf.estimators_[0],
    feature_names=X.columns,
    class_names=[str(cls) for cls in clf.classes_],
    filled=True,
    rounded=True,
    fontsize=10
)
plt.title("Random Forest İçindeki 1. Ağaç")
plt.show()

# Eğitim setinde tahmin ve skor
y_train_pred = clf.predict(X_train_smote)
train_acc = accuracy_score(y_train_smote, y_train_pred)

# Test setinde skor
test_acc = accuracy_score(y_test, y_pred)

print(f"Eğitim seti doğruluğu: {train_acc:.4f}")
print(f"Test seti doğruluğu: {test_acc:.4f}")

if train_acc - test_acc > 0.1:
    print("UYARI: Modelde overfitting olabilir! (Eğitim skoru çok yüksek, test skoru düşük)")
else:
    print("Model overfitting yapmıyor ya da minimal overfitting var.")

import numpy as np
import scipy.stats as st

n_iterations = 1000  # Bootstrap iterasyon sayısı
bootstrapped_scores = []

rng = np.random.RandomState(42)  # Tekrarlanabilirlik için

for i in range(n_iterations):
    # Test setinden bootstrap örneklem (örnekler tekrar seçilebilir)
    indices = rng.choice(len(X_test), size=len(X_test), replace=True)
    X_test_boot = X_test.iloc[indices]
    y_test_boot = y_test.iloc[indices]

    # Tahmin yap
    y_pred_boot = clf.predict(X_test_boot)

    # Doğruluk skorunu hesapla
    score = accuracy_score(y_test_boot, y_pred_boot)
    bootstrapped_scores.append(score)

bootstrapped_scores = np.array(bootstrapped_scores)
mean_score = np.mean(bootstrapped_scores)
sem_score = st.sem(bootstrapped_scores)

# %95 güven aralığı (t-dağılımı ile)
conf_interval = st.t.interval(0.95, df=len(bootstrapped_scores)-1, loc=mean_score, scale=sem_score)

print(f"Bootstrap ile Accuracy ortalaması: {mean_score:.4f}")
print(f"%95 Güven aralığı: ({conf_interval[0]:.4f}, {conf_interval[1]:.4f})")

"""**XGBOOST MODELİ**"""

import pandas as pd
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Özellikler ve hedef değişken
X = df.drop(['Target_encoded', 'Target'], axis=1, errors='ignore')
y = df['Target_encoded']

# Eğitim-test verisi ayırma
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# XGBoost model
xgb_model = XGBClassifier(
    objective='multi:softmax',
    num_class=len(y.unique()),
    eval_metric='mlogloss',
    max_depth=4,
    learning_rate=0.1,
    n_estimators=100,
    random_state=42
)

# Eğitimi gerçekleştir
xgb_model.fit(X_train, y_train)

# Tahmin yap
y_pred = xgb_model.predict(X_test)

# Performans çıktıları
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

import pandas as pd
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE  # SMOTE ekleniyor

# Özellikler ve hedef değişken
X = df.drop(['Target_encoded', 'Target'], axis=1, errors='ignore')
y = df['Target_encoded']

# Eğitim-test verisi ayırma
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42
)

# SMOTE uygulama (sadece eğitim verisine!)
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# XGBoost model
xgb_model = XGBClassifier(
    objective='multi:softmax',
    num_class=len(y.unique()),
    eval_metric='mlogloss',
    max_depth=4,
    learning_rate=0.1,
    n_estimators=100,
    random_state=42
)

# SMOTE ile dengelenmiş veriyle modeli eğit
xgb_model.fit(X_train_smote, y_train_smote)

# Test setiyle tahmin yap
y_pred = xgb_model.predict(X_test)

# Performans çıktıları
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred, digits=4))

import numpy as np
from sklearn.utils import resample

n_iterations = 1000  # bootstrap tekrar sayısı
n_size = len(X_test)
acc_scores = []

for i in range(n_iterations):
    # Test setinden bootstrap örneği oluştur (tekrar ile)
    X_test_resampled, y_test_resampled = resample(X_test, y_test, n_samples=n_size, random_state=42+i)

    # Tahmin yap
    y_pred_resampled = xgb_model.predict(X_test_resampled)

    # Accuracy hesapla
    acc = accuracy_score(y_test_resampled, y_pred_resampled)
    acc_scores.append(acc)

# Güven aralığı
alpha = 0.95
p_lower = ((1.0 - alpha) / 2.0) * 100
p_upper = (alpha + ((1.0 - alpha) / 2.0)) * 100
lower = np.percentile(acc_scores, p_lower)
upper = np.percentile(acc_scores, p_upper)

print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print(f"{int(alpha*100)}% Bootstrap Confidence Interval for Accuracy: [{lower:.4f}, {upper:.4f}]")

!apt-get install graphviz -y
!pip install graphviz

from xgboost import to_graphviz
from PIL import Image
import matplotlib.pyplot as plt

# Modelden dot formatında grafik oluştur
dot = to_graphviz(xgb_model, num_trees=0, rankdir='TB')

# Dot verisini PNG'ye dönüştür
dot.format = 'png'
dot.render('xgb_tree')

# Oluşan PNG dosyasını oku ve göster
img = Image.open('xgb_tree.png')
plt.figure(figsize=(30, 30))
plt.imshow(img)
plt.axis('off')
plt.show()